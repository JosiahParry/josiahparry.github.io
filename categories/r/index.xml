<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on Josiah Parry</title>
    <link>/categories/r/</link>
    <description>Recent content in R on Josiah Parry</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2019</copyright>
    <lastBuildDate>Tue, 11 Jun 2019 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/r/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Google Trends for Campaigns</title>
      <link>/post/trendyy-4-campaigns/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/trendyy-4-campaigns/</guid>
      <description>Over the past few years we have seen Google Trends becoming quite ubiquitous in politics. Pundits have used Google seach trends as talking points. It is not uncommon to hear news about a candidates search trends the days following a town hall or significant rally. It seems that Google trends are becoming the go to proxy for a candidate’s salience.
As a campaign, you are interested in the popularity of a candidate relative to another one.</description>
    </item>
    
    <item>
      <title>Web-scraping for Campaigns</title>
      <link>/post/scraping-4-campaigns/</link>
      <pubDate>Tue, 11 Jun 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/scraping-4-campaigns/</guid>
      <description>As the primaries approach, I am experiencing a mix of angst, FOMO, and excitement. One of my largest concerns is that progressive campaigns are stuck in a sort of antiquated but nonetheless entrenched workflow. Google Sheets reign in metric reporting. Here I want to present one use case (of a few more to come) where R can be leveraged by your data team.
In this post I show you how to scrape the most recent polling data from FiveThirtyEight.</description>
    </item>
    
    <item>
      <title>Introducing trendyy</title>
      <link>/post/2019-05-25-introducing-trendyy/</link>
      <pubDate>Sat, 25 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-05-25-introducing-trendyy/</guid>
      <description>trendyy is a package for querying Google Trends. It is build around Philippe Massicotte’s package gtrendsR which accesses this data wonderfully.
The inspiration for this package was to provide a tidy interface to the trends data.
Getting Started Installation You can install trendyy from CRAN using install.packages(&amp;quot;trendyy&amp;quot;).
 Usage Use trendy() to search Google Trends. The only mandatory argument is search_terms. This is a character vector with the terms of interest.</description>
    </item>
    
    <item>
      <title>genius tutorial</title>
      <link>/post/2019-05-08-genius-learnr-tutorial/</link>
      <pubDate>Wed, 08 May 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/2019-05-08-genius-learnr-tutorial/</guid>
      <description>Introducing genius You want to start analysing song lyrics, where do you go? There have been music information retrieval papers written on the topic of programmatically extracting lyrics from the web. Dozens of people have gone through the laborious task of scraping song lyrics from websites. Even a recent winner of the Shiny competition scraped lyrics from Genius.com.
I too have been there. Scraping websites is not always the best use of your time.</description>
    </item>
    
    <item>
      <title>genius Plumber API</title>
      <link>/post/genius-api/</link>
      <pubDate>Sat, 30 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>/post/genius-api/</guid>
      <description>get started here
Since I created genius, I’ve wanted to make a version for python. But frankly, that’s a daunting task for me seeing as my python skills are intermediate at best. But recently I’ve been made aware of the package plumber. To put it plainly, plumber takes your R code and makes it accessible via an API.
I thought this would be difficult. I was so wrong.
 Using plumber Plumber works by using roxygen like comments (#*).</description>
    </item>
    
    <item>
      <title>xgboost feature importance</title>
      <link>/post/xgb-feature-importance/</link>
      <pubDate>Sat, 01 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/xgb-feature-importance/</guid>
      <description>This post will go over extracting feature (variable) importance and creating a function for creating a ggplot object for it. I will draw on the simplicity of Chris Albon’s post. For steps to do the following in Python, I recommend his post.
If you’ve ever created a decision tree, you’ve probably looked at measures of feature importance. In the above flashcard, impurity refers to how many times a feature was use and lead to a misclassification.</description>
    </item>
    
    <item>
      <title>[Not so] generic functions</title>
      <link>/post/function-methods/</link>
      <pubDate>Wed, 28 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/function-methods/</guid>
      <description>The Jargon The Generic Method The Default Method sf method tbl_graph method Review (tl;dr)   Lately I have been doing more of my spatial analysis work in R with the help of the sf package. One shapefile I was working with had some horrendously named columns, and naturally, I tried to clean them using the clean_names() function from the janitor package. But lo, an egregious error occurred. To this end, I officially filed my complaint as an issue.</description>
    </item>
    
    <item>
      <title>Chunking your csv</title>
      <link>/post/write-chunked-csv/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/write-chunked-csv/</guid>
      <description>Sometimes due to limitations of software, file uploads often have a row limit. I recently encountered this while creating texting campaigns using Relay. Relay is a peer-to-peer texting platform. It has a limitation of 20k contacts per texting campaign. This is a limitation when running a massive Get Out the Vote (GOTV) texting initiative.
In order to solve this problem, a large csv must be split into multiple csv’s for upload.</description>
    </item>
    
    <item>
      <title>Reading Multiple csvs as 1 data frame</title>
      <link>/post/read-chunked-csv/</link>
      <pubDate>Sat, 27 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/read-chunked-csv/</guid>
      <description>In an earlier posting I wrote about having to break a single csv into multiple csvs. In other scenarios one data set maybe provided as multiple a csvs.
Thankfully purrr has a beautiful function called map_df() which will make this into a two liner. This process has essentially 3 steps.
Create a vector of all .csv files that should be merged together. Read each file using readr::read_csv() Combine each dataframe into one.</description>
    </item>
    
    <item>
      <title>Coursera R-Programming: Week 2 Problems</title>
      <link>/post/tidy-coursera-r-programming/</link>
      <pubDate>Sat, 14 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/tidy-coursera-r-programming/</guid>
      <description>Over the past several weeks I have been helping students, career professionals, and people of other backgrounds learn R. During this time one this has become apparent, people are teaching the old paradigm of R and avoiding the tidyverse all together.
I recently had a student reach out to me in need of help with the first programming assignment from the Coursera R-Programming course (part of the Johns Hopkins Data Science Specialization).</description>
    </item>
    
    <item>
      <title>Introducing geniusR</title>
      <link>/post/introducing-geniusr/</link>
      <pubDate>Sat, 27 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/introducing-geniusr/</guid>
      <description>Introducing geniusR geniusR enables quick and easy download of song lyrics. The intent behind the package is to be able to perform text based analyses on songs in a tidy[text] format.
This package was inspired by the release of Kendrick Lamar’s most recent album, DAMN.. As most programmers do, I spent way too long to simplify a task, that being accessing song lyrics. Genius (formerly Rap Genius) is the most widly accessible platform for lyrics.</description>
    </item>
    
  </channel>
</rss>