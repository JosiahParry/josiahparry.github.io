---
title: "xgboost feature importance"
subtitle: "Extracting and plotting feature importance"
slug: xgb-feature-importance
date: "2018-12-01"
categories:
  - R
  - machine learning
tags:
  - R
  - machine learning
  - decision trees
  - tutorial
  - ggplot
---


This post will go over extracting feature (variable) importance and creating a function for creating a ggplot object for it. I will draw on the simplicity of Chris Albon's post. For steps to do the following in Python, I recommend his [post](https://chrisalbon.com/machine_learning/trees_and_forests/feature_importance/). 

<img alt="Feature Importance by Chris Albon" src="https://chrisalbon.com/images/machine_learning_flashcards/Feature_Importance_print.png"/>


If you've ever created a decision tree, you've probably looked at measures of feature importance. In the above flashcard, impurity refers to how many times a feature was use and lead to a misclassification. Here, we're looking at the importance of a feature, so how much it helped in the classification or prediction of an outcome. 

This example will draw on the build in data `Sonar` from the `mlbench` package.

### Prepping the Environment

```{r message=FALSE, warning=FALSE}
library(caret)
library(xgboost)
library(tidyverse)
```

### Loading the data

```{r}
data("Sonar", package = "mlbench")
```

### Train the decision tree

```{r eval=FALSE}
xgb_fit <- train(Class ~ .,
                 data = Sonar,
                 method = "xgbLinear")

```
```{r echo=FALSE}
xgb_fit <- read_rds("../../static/data/sonar_xgb.rds")
```
```{r}
xgb_fit
```

### Extract feature importance

Since we are using the `caret` package we can use the built in function to extract feature importance, or the function from the `xgboost` package. We will do both.

#### `caret` feature importance

```{r}
caret_imp <- varImp(xgb_fit)
caret_imp
```


#### `xgboost` feature importance

```{r}
xgb_imp <- xgb.importance(feature_names = xgb_fit$finalModel$feature_names,
               model = xgb_fit$finalModel)

head(xgb_imp)
```


### Plotting feature importance

#### caret

You have a few options when it comes to plotting feature importance. You can call plot on the saved object from caret as follows:

```{r}
plot(caret_imp)
```

```{r}
ggplot(caret_imp) +
  theme_minimal()
```

#### `xgboost`

You can use the plot functionality from `xgboost`

```{r}
xgb.plot.importance(xgb_imp)
```
Or use their ggplot feature

```{r}
xgb.ggplot.importance(xgb_imp)
```

